[
  {
    "timestamp": 1764719900.8287184,
    "type": "run_metadata",
    "text": "Started new session with input: What do you know about Don Tapscott and Anthony Williams? at 2025-12-02T23:58:20.828718",
    "tool_name": null,
    "tool_args": null,
    "tool_result": null,
    "final_answer": null,
    "tags": [
      "run_start"
    ],
    "success": null,
    "metadata": {
      "start_time": "2025-12-02T23:58:20.828718",
      "step": 0
    }
  },
  {
    "timestamp": 1764719907.7410743,
    "type": "tool_output",
    "text": "Output of solve_sandbox: {'result': \"FINAL_ANSWER: Don Tapscott and Anthony D. Williams are the authors of 'Wikinomics: How Mass Collaboration Changes Everything', which was first published in December 2006. The book discusses the reinvention of the web as a global platform for collaboration.\"}",
    "tool_name": "solve_sandbox",
    "tool_args": {
      "plan": "async def solve():\n    # NO FUNCTION_CALL - Data already provided in user input\n    # When user_input contains \"Your last tool produced this result:\" with search results showing:\n    # - Titles and summaries\n    # - Multiple search results with URLs\n    # DO NOT call the search tool again!\n    \n    # Extract information from the provided search results and synthesize answer\n    answer = \"Don Tapscott and Anthony D. Williams are the authors of 'Wikinomics: How Mass Collaboration Changes Everything', which was first published in December 2006. The book discusses the reinvention of the web as a global platform for collaboration.\"\n    \n    # FINAL_ANSWER - synthesize from data already in user_input\n    return f\"FINAL_ANSWER: {answer}\""
    },
    "tool_result": {
      "result": "FINAL_ANSWER: Don Tapscott and Anthony D. Williams are the authors of 'Wikinomics: How Mass Collaboration Changes Everything', which was first published in December 2006. The book discusses the reinvention of the web as a global platform for collaboration."
    },
    "final_answer": null,
    "tags": [
      "sandbox"
    ],
    "success": true,
    "metadata": {}
  },
  {
    "timestamp": 1764719923.6191845,
    "type": "run_metadata",
    "text": "Started new session with input: What is the relationship between Gensol and Go-Auto? at 2025-12-02T23:58:43.619184",
    "tool_name": null,
    "tool_args": null,
    "tool_result": null,
    "final_answer": null,
    "tags": [
      "run_start"
    ],
    "success": null,
    "metadata": {
      "start_time": "2025-12-02T23:58:43.619184",
      "step": 0
    }
  },
  {
    "timestamp": 1764719935.3545785,
    "type": "tool_output",
    "text": "Output of solve_sandbox: {'result': 'FINAL_ANSWER: Gensol and Go-Auto are related through financial transactions, particularly those involving the purchase of EVs. Funds were transferred from Gensol to Go-Auto, ostensibly for EV purchases. There are investigations into these transactions, with concerns raised about the legitimacy and use of these funds.'}",
    "tool_name": "solve_sandbox",
    "tool_args": {
      "plan": "import json\nasync def solve():\n    # NO FUNCTION_CALL - Data already provided in user input\n    # The search results indicate a relationship between Gensol and Go-Auto, primarily involving financial transactions related to EV purchases.\n\n    # Extract information from the provided search results and synthesize answer\n    answer = \"Gensol and Go-Auto are related through financial transactions, particularly those involving the purchase of EVs. Funds were transferred from Gensol to Go-Auto, ostensibly for EV purchases. There are investigations into these transactions, with concerns raised about the legitimacy and use of these funds.\"\n\n    # FINAL_ANSWER - synthesize from data already in user_input\n    return f\"FINAL_ANSWER: {answer}\""
    },
    "tool_result": {
      "result": "FINAL_ANSWER: Gensol and Go-Auto are related through financial transactions, particularly those involving the purchase of EVs. Funds were transferred from Gensol to Go-Auto, ostensibly for EV purchases. There are investigations into these transactions, with concerns raised about the legitimacy and use of these funds."
    },
    "final_answer": null,
    "tags": [
      "sandbox"
    ],
    "success": true,
    "metadata": {}
  },
  {
    "timestamp": 1764719980.1098466,
    "type": "run_metadata",
    "text": "Started new session with input: Summarize this page: https://theschoolof.ai/ at 2025-12-02T23:59:40.109846",
    "tool_name": null,
    "tool_args": null,
    "tool_result": null,
    "final_answer": null,
    "tags": [
      "run_start"
    ],
    "success": null,
    "metadata": {
      "start_time": "2025-12-02T23:59:40.109846",
      "step": 0
    }
  },
  {
    "timestamp": 1764720031.392274,
    "type": "tool_output",
    "text": "Output of solve_sandbox: {'result': 'FINAL_ANSWER: The School of AI (TSAI) offers courses in AI, ML, and deep learning. Their courses, ERA, EAG, and EPAi, have trained over 7000 students. ERA focuses on training LLMs from scratch, EAG focuses on Agents and EPAi is a Python and programming for AI course. EAG V2 will be in April 2026. ERA V4 introduces an exceptional course structure and includes Real-World, Full-Scale LLM Training, Practical CoreSet Focus, Multi-GPU ImageNet Training, Quantization Aware Training (QAT), and Balanced Inclusion of RL + VLMs + Embeddings. EPAi is an advanced Python course for those wanting to become application and ML Architects.'}",
    "tool_name": "solve_sandbox",
    "tool_args": {
      "plan": "async def solve():\n    # NO FUNCTION_CALL - Data already provided in user input\n    # The user_input contains \"Your last tool produced this result:\" with clean extracted webpage content.\n\n    content = \"\"\"A disciplined and structured approach to learning and implementing the fundamentals of AIML.\n\n    through bleeding edge concepts, and an amazing peer group to learn with.\n\n    Through ERA, EAG and EPAi, TSAI has trained more than 7000 students! In ERA we learn how to \"actually\" train LLMs from scratch. EAG focuses on Agents, and EPAi is a comprehensive course focusing on Python and programming for AI!\n\n    This comprehensive 20-session course equips students to build advanced Agentic AI systems, capable of autonomous decision-making, task orchestration, and seamless interaction within complex web environments. Unlike traditional AI programs, this curriculum focuses on designing browser-based agents that leverage the latest advancements in LLMs, retrieval-augmented systems, and multi-agent collaboration, preparing students to lead the development of next-generation AI solutions.\n\n    This course **does not teach** how to use langChain, langGraph, crew.ai or n8n! This course is about making such, and more advanced multi-model Agentic Frameworks and Agents on top of them.\n\n    The EAG course offers a revolutionary approach to learning AI, enabling students to design agents that mirror human-like intelligence in interacting with the web, bridging the gap between theory and application.\n\n    Registrations are closed now. Registrations for EAG V3 are scheduled to be in April 2026.\n\n    EAG V2\n\n    | Lecture Title |\n    |---|\n\n    | Session 1: Transformers & LLM Foundations \u2013 Understand how transformer architecture and large language models work at their core. |\n    | Session 2: Modern LLM Internals + SFT Basics \u2013 Explore pretraining internals, scaling rules, and the fundamentals of supervised fine-tuning. |\n    | Session 3: What Makes an Agent? Reactive vs. Proactive \u2013 Learn the traits and trade-offs between reactive and goal-driven AI agents. |\n    | Session 4: Tool Protocols 101 (HTTP, JSON-RPC, schema validation) \u2013 Master communication protocols and schema-driven tool integration. |\n    | Session 5: Model Context Protocol & Interop Standards \u2013 Discover MCP and other standards enabling cross-platform agent interoperability. |\n    | Session 6: Planning & Reasoning (CoT, Structured, Self-Consistency) \u2013 Apply structured reasoning techniques for accurate, multi-step problem-solving. |\n    | Session 7: Agent Architecture \u2013 Cognitive Layers \u2013 Design agents with perception, memory, and decision-making layers for robust performance. |\n    | Session 8: RAG & Memory Architectures \u2013 Build agents with retrieval-augmented generation and efficient memory management. |\n    | Session 9: Tool Use: Secure API & Command Execution \u2013 Enable agents to safely execute APIs and commands within controlled environments. |\n    | Session 10:Hybrid Planning (AI + Heuristics) \u2013 Combine LLM reasoning with traditional heuristics for optimal decision-making. |\n    | Session 11:Multi-Agent Systems & Meta-Agents \u2013 Coordinate multiple agents to work collaboratively on complex goals. |\n    | Session 12:Environment-Aware Agents (Web + Desktop) \u2013 Equip agents to perceive and act within both browser and desktop environments. |\n    | Session 13:Perception: Multimodal Input Handling \u2013 Integrate text, image, audio, and other modalities into unified agent perception. |\n    | Session 14:Sandboxed Execution & Safety \u2013 Run agent actions in secure sandboxes to ensure reliability and prevent harm. |\n    | Session 15:Scaling Agents Across Machines \u2013 Architect systems for distributed, multi-machine agent deployment. |\n    | Session 16:Intelligent Goal Interpretation \u2013 Train agents to interpret, refine, and align with human goals accurately. |\n    | Session 17:Managing Uncertainty & Error Recovery \u2013 Handle ambiguity and implement robust error-correction strategies. |\n    | Session 18:Agent Debugging & Introspection \u2013 Monitor, debug, and refine agents through introspection and trace analysis. |\n    | Session 19:Evaluation & Continuous Improvement \u2013 Measure agent performance and iterate for ongoing enhancement. |\n    | Session 20:Capstone: Autonomous Environment-Aware Agent \u2013 Design, build, and demo a fully autonomous, environment-aware AI agent. |\n\n    EAG V1\n\n    | Lecture Title |\n    |---|\n\n    | Session 1: Foundations of the Transformer Architecture - A deep dive into the self-attention mechanism and why Transformers revolutionized NLP. |\n    | Session 2: Modern Language Model Internals - Examines pre-training objectives, parameter scaling, and advanced fine-tuning for LLMs. |\n    | Session 3: Introduction to Agentic AI - Overviews AI agents that plan, reason, and take actions beyond simple text generation. |\n    | Session 4: Planning and Reasoning with Language Models - Covers chain-of-thought prompting, multi-step reasoning, and structured thinking in LLMs. |\n    | Session 5: Agent Architecture \u2013 Cognitive Layers - Explores layered designs for perception, memory, and action to build robust AI agents. |\n    | Session 6: Memory, Context, and State Management - Focuses on methods (vector stores, retrieval-augmented generation) for handling extended context. |\n    | Session 7: Tool Use and External APIs - Shows how agents can call external tools or APIs (including Python scripts) to augment capabilities. |\n    | Session 8: Reinforcement Learning for Agentic Behaviors - Introduces RL frameworks that let agents learn and adapt through trial and error. |\n    | Session 9: Advanced Prompt Engineering & Auto-Prompting - Teaches sophisticated prompting tactics, sub-prompts, and self-improving prompt loops. |\n    | Session 10: Retrieval-Augmented and Knowledge-Graph Agents - Examines how external knowledge sources (search, databases, graphs) ground agent outputs. |\n    | Session 11: Understanding Browser Based Agents - Introduces AI-powered browser assistants and demonstrates their high-level architecture. |\n    | Session 12: Fundamentals of Web Page Parsing - Presents core HTML parsing, DOM traversal, and techniques to extract meaningful data from pages. |\n    | Session 13: Context Maintenance in Browsers - Shows how to persist and manage session data while browsing across multiple tabs/sites. |\n    | Session 14: Building Browser-Aware Agents - Covers leveraging browser-specific APIs to let agents navigate, click, and interact with pages. |\n    | Session 15: Introduction to Browser Automation Tools - Surveys Selenium, Puppeteer, and Playwright, focusing on bridging them with agentic frameworks. |\n    | Session 16: Intelligent Goal Interpretation - Explores designing agents that align web automation tasks with user-defined objectives. |\n    | Session 17: Multi-Agent Systems and Collaboration - Demonstrates how multiple agents can coordinate across different browser tasks or subtasks. |\n    | Session 18: Managing Uncertainty and Error Correction - Equips you with strategies for handling dynamic web structures, unexpected failures, and retries. |\n    | Session 19: Advanced Task Orchestration - Guides you through synchronizing tasks, tabs, and user interactions in real time. |\n    | Session 20: Capstone \u2013 (Probably) Autonomous Browser Assistant - Challenges you to design, build, and demo a fully functioning browser-based AI with advanced features. |\n\n    ERA is a course focusing on how to learn \"how to train a Large Language models from scratch\". It is a meticulously designed course that offers a comprehensive, hand-on learning experience in modern AI. Though the course is intended for beginners, this course has a steep learning curve. Please join only if you can promise yourself tremendous amount of commitment, discipline, and heart/time to immerse yourself into pure learning for 6 odd months! If you're ready to immerse yourself fully, we promise an experience like no other \u2014 one that will teach you things you simply won't find anywhere else\n\n    **ERA V4** introduces a new course structure which is **exceptional**, forward-looking and ambitious in a way that **no mainstream curriculum** is right now.\n\n    **Real-World, Full-Scale LLM Training**\n\n    **Practical CoreSet Focus**\n\n    **Multi-GPU ImageNet Training**\n\n    **Quantization Aware Training (QAT) as first-class citizen**\n\n    **Balanced Inclusion of RL + VLMs + Embeddings**\n\n    We hope you'll enjoy learning in ERA V4 as much as we've loved creating it!\n\n    ERA V4\n\n    | Lecture Title |\n    |---|\n\n    | Session 1: Introduction to AI, Neural Networks and Development Tools |\n    | Session 2: Python Essentials, Version Control, and Web Development Basics |\n    | Session 3: PyTorch Fundamentals and AWS EC2 101 |\n    | Session 4: Building First Neural Network and Training on Cloud |\n    | Session 5: CNNs and Backpropagation |\n    | Session 6: In-Depth Coding Practice - CNNs |\n    | session focused on deepening understanding of CNN implementatio |\n    | Session 7: Advanced CNN Architectures & Trainng |\n    | Session 8: One Cycle Policy and CoreSet Training |\n    | Session 9: Multi-GPU Training of ResNet from Scratch on Full ImageNet |\n    | Session 10: Introduction to Transformers and Emergent Abilities in LLMs |\n    | Session 11: Embeddings, Tokenization, and CoreSets |\n    | Session 12: Transformer Architectures, MHA and LLM Training |\n    | Session 13: Optimization Techniques, RoPE, CoreSets & LLM Evaluations |\n    | Session 14: Full Quantization-Aware Training (not LoRA or PEFT) |\n    | Session 15: CLIP and Vision-Language Models (VLMs) |\n    | Session 16: Reinforcement Learning 101 |\n    | Session 17: Continuous Action Spaces in RL |\n    | Session 18: RLHF, GPRO and Instruction Fine-Tuning for LLMs |\n    | Session 19: Pretraining a 70B LLM End-to-End, followed by Instruction Tuning |\n    | Session 20: Capstone |\n\n    ERA V3\n\n    | Lecture Title |\n    |---|\n\n    | Session 01: Introduction to AI, Neural Networks, and Development Tools |\n    | Session 02: Python Essentials, Version Control, and Web Development Basics |\n    | Session 03: Data Representation, Preprocessing, and UI Integration |\n    | Session 04: PyTorch Fundamentals and Simple Neural Networks |\n    | Session 05: Introduction to Deployment, CI/CD, and MLOps Basics |\n    | Session 06: Convolutional Neural Networks and Training on Cloud (CNNs) |\n    | Session 07: In-depth Coding Practice - CNNs |\n    | Session 08: Introduction to Transformers and Attention Mechanisms |\n    | Session 09: Advanced Neural Network Architectures |\n    | Session 10: Introduction to Large Language Models (LLMs) |\n    | Session 11: Data Augmentation and Preprocessing |\n    | Session 12: Advanced CI/CD, MLOps, and Deployment Practices |\n    | Session 13: Frontend Development for AI Applications |\n    | Session 14: Optimization Techniques and Efficient Training |\n    | Session 15: Visualization Techniques for CNNs and Transformers |\n    | Session 16: Generative Models: VAEs and GANs |\n    | Session 17: Stable Diffusion and Advanced Generative Techniques |\n    | Session 18: LLM Fine-Tuning and Optimization |\n    | Session 19: LLM Inference and Serving |\n    | Session 20: In-depth Coding Practice - LLMs |\n    | Session 21: LLM Agents and AI Assistants |\n    | Session 22: Multi-modal AI Models |\n    | Session 23: Retrieval-Augmented Generation (RAG) |\n    | Session 24: Advanced MLOps and Data Engineering |\n    | Session 25: Edge AI and Mobile Deployment |\n    | Session 26: Cloud Computing and Scalable AI |\n    | Session 27: In-depth Coding Practice - Scaling Up |\n    | Session 28: Reinforcement Learning Fundamentals |\n    | Session 29: End-to-End Project Deployment - A Hands-On |\n    | Session 30: Capstone Project Work |\n\n    Checkout the full course syllabus for ERA V4 and what's new compared to ERA V3.\n\n    An advanced Python course for fundamental understanding of Python Language and the PyTorch library. Designed for those who want to become application and ML Architects.\n\n    This course is not for beginners. Take this sample test to see what you would be learning.\n\n    Registrations for V6 are scheduled in April 2026, subscribe here to be notified.\n\n    PHASE #1 - FUNCTIONAL PYTHON\n\n    | Lecture Title |\n    |---|\n\n    Basics: Python Type Hierarchy, Multi-line statements and strings, Variable Names, Conditionals, Functions, The While Loop, Break Continue and the Try Statement, The For Loop and Classes |\n    Object Mutability and Interning: Variables and Memory References, Garbage Collection, Dynamic vs static Typing, Variable Re-assignment, Object Mutability, Variable Equality, Everything is an Object and Python Interning |\n    Numeric Types I: Integers, Constructors, Bases, Rational Numbers, Floats, rounding, Coercing to Integers and equality |\n    Numeric Types II: Decimals, Decimal Operations, Decimal Performance, Complex Numbers, Booleans, Boolean Precedence and Comparison Operators |\n    Functional Parameters: Argument vs Parameter, Positional and keyword Arguments, Unpacking Iterables, Extended Unpacking, __*args_, Keyword Arguments, __**kwags_, Args and Kwargs together, Parameter Defaults and Application |\n    First Class Functions Part I: Lambda Expressions, Lambdas and Sorting, Functional Introspection, Callables, Map, Filter, Zip and List Comprehension |\n    First Class Functions Part II: List Comprehension, Reducing functions, Partial Functions, Operator Module, Docstrings and Annotations. |\n    Scopes and Closures: Global and Local Scopes, Nonlocal scopes, Closures, and Closure Applications |\n    Decorators: Decorators and Decorator applications (timers, logger, stacked decorators, memoization, decorator class and dispatching) |\n    Tuples and Named Tuples: Tuples, Tuples as data structures, named Tuples, DocStrings, and Application |\n    Modules, Packages and Namespaces: Module, Python Imports, importlib, import variants, reloading modules, __main__, packages, structuring, and namespaces |\n    fStrings, Timing Functions and Command Line Arguments: Dictionary Ordering, kwargs, tuples, fStrings, Timing Functions and Command Line Arguments |\n    Sequence Types I: Sequence Types, Mutable Sequence Types, List vs Tuples, Index Base and Slice Bounds, Copying Sequence and Slicing |\n    Sequence Types II and Advanced List Comprehension: Custom Sequences, In-place Concatenation and Repetition, Sorting Sequences, List Comprehensions + Small Project |\n    Iterables and Iterators: Iterating Collections, Iterators, Iterables, Cyclic Iterators, in-built Iterators, iter() function and iterator applications |\n    Generators and Iteration Tools: Yielding and Generator Functions, Generator Expressions, Yield From, Aggregators, Chaining and Teeing, Zipping and their applications |\n    Context Managers: Context Managers, Lasy Iterators, Generators and Context Managers, Nested Context Managers and their application |\n    Data Pipelines: Data Pipeline and application |\n\n    Phase #2 - OOPS & PYTORCH\n\n    | Lecture Title |\n    |---|\n\n    Hash Maps and Dictionaries: Associative Arrays, Hash Maps, Hash Functions, Dictionary Views, Handling Dictionaries and Custom Classes |\n    Sets and Serialized Dictionaries: Set Theory, Python Sets, Frozen Sets, and Set Applications, DefaultDict, OrderedDict, Counters and UserDict |\n    Serialization and Deserialization: Picking, JSON Serialization, Encoding and Decoding JSON, and Applications |\n    Classes Part I: Object and Classes, Attributes, Callables, Functional Attributes and Run-time attributes |\n    Classes Part II + DataClasses: Properties, Decorators, Read-Only Properties, Class and Static Methods, Scopes, Dataclasses and Application |\n    Polymorphism and Special Methods: Polymorhpism, __str__ and __repr__ methods, rich comparisons, hashing and equality, callables, and applications |\n    Single Inheritance: Single Inheritance, Object Class, Overriding, Extending, Delegation, Slots, and applications |\n    Descriptors: Descriptors, Getters and Setters, Instance Properties, Strong and Weak References, __set_name__ method, Proprty Lookup Resolution and application |\n    Enumerations and Exceptions: Enumerations, Aliases, Custom Enums, Python Exceptions, Handling and Raising Exceptions and creating custom exceptions |\n    Pytorch Basics I : Matrices, Tensors, Variables, Numpy and PyTorch inter-operability, Rank, Axes and Shapes |\n    PyTorch Basics II: Data and Dataloader, Forward Method, Training Loop and Training Pipeline |\n    PyTorch Intermediate I + Pytorch Internals:PyTorch Classes, Containers, Layers and Activations. PyTorch Internals or how Pytorch uses Advanced Python internally |\n    PyTorch Intermediate II: Distance and Basic Loss Functions, Utilities, Profiling Layers, MACs/FLOPs calculations and Memory Usage |\n    PyTorch Advanced I: Convolution Algorithm Implementation, Autograd Mechanics and Dynamic Computation Graph |\n    PyTorch Advanced II: Optimizers, Custom Dataloaders, Tensorboard Integration, Memory Management and Half Precision Training |\n    PyTorch Advanced III: Advanced Loss Functions for GAN, Kullback Lieber, Embeddings, Focal, IoU, Perceptual, CTC, Triplet and DICE |\n\n    Course Feedback\n\n    | Feedback from Phase 1 students moving to Phase 2 |\n    |---|\n\n    | Initially i thought it would be just like all other python course, i joined just thinking i might learn few things more.. but as session progressed i was like.. okay i dont know python.. amazing sessions and course content |\n    | A very in depth course and excellent concepts |\n    | I really liked the course content. I never learnt python in this much depth. Now I can say that I am a python developer \\ud83d\\ude0a |\n    | Slightly hectic, when it comes to assignment submission.More days(atleast week time should be given for assignment submission) |\n    | ONE OF THE BEST COURSE AT AFFORDABLE PRICE |\n    | Has helped me know about intricate things on python |\n    | Course content is good and in depth which makes it easy to understand for anyone |\n    | Seriously EPAi one of the best Intermediate Python Courses that I have taken up. In-depth Content, Fun-To-Do Assignments, what else do I need? |\n    | Honestly i learned a lot from this course.. Course contents are really good and covered in depth which i really liked. |\n    | It is really awesome course !!! Good in-depth sessions. |\n    | For me course really helped a lot. Got to learn many new things. |\n    | Course is well structure but would request for more time for the assignment submissions. Like other courses a week should be good in my opinion. |\n    | Excellent stuff |\n    | Very nice course I learned a lot |\n    | The course content is very well structured and assignments are also top notch |\n    | Excellent course |\n    | This course is extremely unique. Not surprised as it's from TSAI. My overall experience with TSAI has been amazing ever since. |\n    | Hits the very core foundation of important concepts |\n    | One of the best courses I have ever attended |\n    | Good course content, too fast pace, challenging assignments |\n    | Gives in depth knowledge about the design and working behaviour of python |\n    | Advanced course in python which teaches CI/CD as an extra practice. |\n    | It's very good |\n    | Its great course for Advance Pythons for AI |\n    | good platform to explore so many new concepts |\n    | In-depth understanding of python for writing optimized, error-free and modular codes. Creating our own packages and module. |\n    | Course content is good and touching the deep roots of python |\n    | The course is very useful for me, I have not seen a course with this good content online. |\n    | its beautiful |\n    | Awesome, worth it |\n    | I think it's a very exhaustive course and is really going to be useful for my career. |\n\n    Instructor Feedback\n\n    | Feedback from Phase 1 students moving to Phase 2 |\n    |---|\n\n    | ABOUT THE INSTRUCTOR |\n    | I joined because you were teaching |\n    | Take a bow |\n    | What can I say, he is the best person to teach this course |\n    | Too good |\n    | BEST I CAN SAY. ROHAN SHRAVAN IS MY NEW ROLE MODEL. I WISH HIM SUCCESS FOR HIS FUTURE PLANS. |\n    | PRO |\n    | Rohan is an amazing instructor and makes every attempt to clarify things |\n    | G.O.D |\n    | One of the best instructor and influencer i have seen in my life. |\n    | Fabulous. Please take some more courses like this - C++, Javascript. |\n    | When i think of Rohan, I see dedication, commitment and discipline. when i look back i see much change in me. Thank you very much Rohan. |\n    | Good as always |\n    | Instructor is awesome like always! |\n    | Class apart |\n    | good |\n    | Knowledgeable |\n    | Excellent |\n    | Knowledgeable |\n    | Awesome |\n    | Awesome |\n    | Good hardworking |\n    | Perfect |\n    | Good |\n    | Extremely knowledgeable and experienced. Honoured to have such a mentor |\n    | Knowledgeable, explains even the tiniest detail |\n    | Rohan is very very very knowledgeable. And more than that, he is an awesome and inspirational teacher. He knows the issues that the students might face and keep his content and hands on session based on these factors. |\n    | Man! No comments! |\n    | Perfect to describe in one word and easily one of the best teachers I have studied under in my life yet |\n    | expert in python |\n    | Good |\n    | One of the finest instructor from whom I have taken the course |\n    | He gives great insight into topic taken |\n    | Excellent & Has lot of passion & patience |\n    | He is well knowledge in the topics |\n    | Rohan has ability to deliver complex concepts in a nice and simple yet powerful way. |\n    | Rohan is awesome. |\n    | Rohan is exceptional. |\n    | cant get better |\n    | I don't think it can get better than Rohan. Its his humble nature and passion that he brings to each class that drives me. |\n\n    A cutting-edge course for mastering the art of managing and deploying machine learning models at scale.\n\n    This course is not for the beginners.\n\n    EMLO is merged with the ERA Course\n\n    EMLO 4.0\n\n    | Lecture Title |\n    |---|\n\n    | Session 1 - Introduction to MLOps: An overview of MLOps (Machine Learning Operations), covering the best practices and tools to manage, deploy, and maintain machine learning models in production. |\n    | Session 2 - Docker - I: A hands-on session on creating Docker containers from scratch and an introduction to Docker, the containerization platform, and its core concepts. |\n    | Session 3 - Docker - II: An introduction to Docker Compose, a tool for defining and running multi-container Docker applications, with a focus on deploying machine learning applications. |\n    | Session 4 - PyTorch Lightning - I: An overview of PyTorch Lightning, a PyTorch wrapper for high-performance training and deployment of deep learning models, and a project setup session using PyTorch Lightning. |\n    | Session 5 - PyTorch Lightning - II: Learn to build sophisticated ML projects effortlessly using PyTorch Lightning and Hydra, combining streamlined development with advanced functionality for seamless model creation and deployment. |\n    | Session 6 - Data Version Control (DVC): Data Version Control (DVC), a tool for managing machine learning data and models, including versioning, data and model management, and collaboration features. |\n    | Session 7 - Experiment Tracking & :yperparameter Optimization A session covering various experiment tracking tools such as Tensorboard, MLFlow and an overview of Hyperparameter Optimization techniques using Optuna and Bayesian Optimization. |\n    | Session 10 - AWS Crash Course: A session on AWS, covering EC2, S3, ECS, ECR, and Fargate, with a focus on deploying machine learning models on AWS. |\n    | Session 11 - Model Deployment w/ FastAPI: A hands-on session on deploying machine learning models using FastAPI, a modern, fast, web framework for building APIs. |\n    | Session 12 - Model Deployment w/ TorchServe: An introduction to TorchServe, a PyTorch model serving library, and a hands-on session on deploying machine learning models using TorchServe. |\n    | Session 13 - Kubernetes - I: This session provides an introduction to Kubernetes, a popular container orchestration platform, and its key concepts and components. |\n    | Session 14 - Kubernetes - II: In this session, participants will learn how to monitor and configure Kubernetes clusters for machine learning workloads. |\n    | Session 15 - Kubernetes - III: This session will cover introduction to EKS, Kubernetes Service on AWS, Deploying a FastAPI - PyTorch Kuberentes Service on EKS |\n    | Session 16 - Kubernetes - IV: This session covers EBS Volumes, ISTIO and KServe, learning to deploy pytorch models on KServe |\n    | Session 17 - Canary Deployment & Monitoring: This session covers how to deploy models with Canary Rollout Strategy while monitoring it on Prometheus and Grafana |\n    | Session 18 - Capstone: This session is a final project where participants will apply the knowledge gained throughout the course to develop and deploy an end-to-end MLOps pipeline. |\n\n    Download the full course syllabus here.\n\n    EVA was the most exhaustive and updated Deep Vision Program in the world! It was spread over three semester-style phases, each restricted by a qualifying exam. It has now been merged into ERA.\n\n    Phase #1\n\n    | Fundamentals of DNNs & Transformes |\n    |---|\n\n    1: Background & Basics: Machine Learning Intuition |\n    1.5: Python: Python 101 for Machine Learning (Handson [HO] 1) |\n    2: Neural Architecture: Convolutions, Pooling Operations & Channels |\n    2.5: PyTorch & Lightning: PyTorch 101 for Vision Machine Learning [HO2] |\n    3: First Neural Network: Kernels, Activations, and Layers |\n    4: Architectural Basics: Building blocks of DNNs |\n    5: Coding Drill Down: We go through 9 model iterations together, step-by-step to find the final architecture [HO3] |\n    6: Mathematical Foundation: For ML & Backpropagation [HO4] |\n    7: Advanced Convolutions & Augmentation: Introduction to Advanced Conv Concepts & Albumentations LIbrary |\n    8: RFs & Attention: RFs & Attention is all you need! |\n    9: Advanced Training & LRs: Class Activation Maps, Optimizers, LR Schedules, LR Finder & One Cycle Policy |\n    10: Super Convergence: Training Models at lightning speed [HO5] |\n    11: Transformers : Deepdive Coding into Transformers [HO6] |\n    12: ViT: Vision Transformers |\n    13: YOLO Part 1: Object Detection (Data Collection and Processing) |\n    14: YOLO Part 2: Training an Object Detector [HO7] |\n    15: Capstone: Your turn now! Qualifying Exam for Phase 2 |\n\n    Phase #2\n\n    | Phase #2 - Transformers & Stable Diffusion |\n    |---|\n\n    16: Transformers and Attention Refresher (HandsOn 8) |\n    17: Attention and its Types |\n    18: Vision Transformers Part 1 |\n    19: Vision Transformers - ViT Part 2 (HandsOn 9) |\n    20: Self-Distillation and Self-Supervised Vision Transformers |\n    21: Introduction to Embedding and Language Models |\n    22: Language Model via Transformers (HandsOn 10) |\n    23: Advanced Concepts in Training Transformers (HandsOn 11) |\n    24: Semantic Segmentation |\n    25: Generative Adversarial Networks (HandsOn 12) |\n    26: Variational AutoEncoders & Mathematics |\n    27: VAE, its types, and Training (HandsOn 13) |\n    28: CLIP & Other Advanced Training Concepts (HandsOn 14) |\n    29: Generative AI and Stable Diffusion |\n    30: Capstone Project |\n\n    Phase #3\n\n    | Phase #3 - Applications |\n    |---|\n\n    31: Model Quantization & Training Part 1 |\n    32: Model Quantization & Training Part 2 |\n    33: Optical Character Recognition |\n    34: Depth Estimation |\n    35: Image Deblurring, Denoising & Enhancement |\n    36: Image Super Resolution |\n    37: Video Super Resolution |\n    38: Pose Estimation |\n    39: Face Recognition |\n    40: Understanding Audio for DNNs |\n    41: Audio Classification & Noise Removal |\n    42: Speech Enhancement & Separation |\n    43: Automatic Speech Recognition |\n    44: Beam Search for STT & NLP |\n    45: Capstone Project Speech Stable Diffusion! |\n    Bottom Topics will soon be moved to another course on Reinforcement learning |\n    Reinforcement Learning Basics: Markov Decision Processes, Deterministic, and Stochastic Environments & Bellman Equation |\n    Q-Learning: Q-Learning, Plan vs Policy Networks, and Environment Models |\n    Deep Q-Learning & DeepTraffic: Custom Environments, OpenGym, Exploration vs Exploitation, and improvements to DQN |\n    Deep Reinforcement Learning: Policy Gradients, Dynamic Programming, Policy Evaluations, and Temporal Difference Learning |\n    Actor-Critic Models: Memory Structures, Gibbs Softmax, Eligibility Traces, and Polyak Averaging |\n    A3C Models: A3C, A3C optimizations, and implementation logic |\n    Deep Deterministic Policy Gradients: DDPG Background, Off-Policy Networks, Continuous Action Spaces, and Replay Buffers |\n    Twin Delayed DDPG Part 1: Clipped Double-Q Learning, Delayed Policy Updates, and Target Policy Smoothing |\n    Twin Delayed DDPG Part 2: Full TD3 implementation to make a robot walk, and solve a custom environment |\n    Autonomous Robotics Introduction: Introduction to ARI platform, and its control systems. Real Robot we mean! |\n    Sensor Fusion for Localization: Sensor fusion, depth estimation, and stereo imaging for robotic localization |\n    3D Environmental Reconstruction Part 1: Solving 3D mapping for static environment |\n    3D Environmental Reconstruction Part 2: Solving 3D mapping for dynamic (moving) objects in the static environment |\n    3D Environmental Reconstruction Part 3: Solving 3D mapping for dynamic objects in a dynamic environment |\n    Advanced Path planning, and Navigation: A*, and other Path planning, and algorithms |\n    EndGame: CapStone project to implement everything we learned |\n    | The later part of this course's topics are inspired from Udacity Nanodegree but only just the topics, not its contents. We would be implementing these on a real robot, without ROS, and using TD3, not DQN as in Udacity |\n\n    In our flagship NLP program, we had ditch RNN/LSTMS and other recurrent networks completely, and focused fully on Transformers. After covering the basics of Neural Networks, we focused on Attention is All you need then covering advanced transformers like BERT, BART, ending with Retrieval Augmented Generation.\n\n    The world since last year moved on, and so has END. END is now merged with ERA.\n\n    PHASE #1 - Transformers\n\n    | Lecture Title |\n    |---|\n\n    | Background and Basics of Modern NLP |\n    | From Embeddings to Language Models |\n    | Advanced Python for General Computing & NLP |\n    | PyTorch for NLP |\n    | RNNs are dead and their Renewed Relevance |\n    | GRUs, Seq2Seq and Attention Mechanism |\n    | HandsOn Training 1 |\n    | Deep NLP using Convolutions |\n    | HandsOn Training 2 |\n    | Attention and Memory in Deep NLP |\n    | HandsOn Training 3 |\n    | Transformers with Linear Attention |\n    | HandsOn Training 4 |\n    | GloVe, Memory Networks and Recap |\n    | Infinity Capstone Project |\n\n    Phase #2 - GPT\n\n    | Lecture Title |\n    |---|\n\n    | Transformers and Attention Mechanism - Overview |\n    | Reformer: the efficient transformer |\n    | Bi-Directional Transformers |\n    | Document Level Models & Contextual Representations |\n    | GPT1 & Models of Dialog |\n    | GPT1 Coding & Practice |\n    | Building and training GPT2 and BERT |\n    | GPT2 and BERT Coding & Practice |\n    | GPT3 Deep Dive: Part 1 Architecture & Preprocessing |\n    | GPT3 Deep Dive: Part 2 Training |\n    | GPT3 Coding & Practice 1 |\n    | GPT3 Coding & Practice 2 |\n    | GPT3 Coding & Practice 3 |\n    | Advanced NLP Over the Edge |\n    | Endgame Capstone Project |\n\n    ** ERA V5 (Transformers & LLMs)** - Registrations will open in Feb 2026.\"\"\"\n\n    summary = \"The School of AI (TSAI) offers courses in AI, ML, and deep learning. Their courses, ERA, EAG, and EPAi, have trained over 7000 students. ERA focuses on training LLMs from scratch, EAG focuses on Agents and EPAi is a Python and programming for AI course. EAG V2 will be in April 2026. ERA V4 introduces an exceptional course structure and includes Real-World, Full-Scale LLM Training, Practical CoreSet Focus, Multi-GPU ImageNet Training, Quantization Aware Training (QAT), and Balanced Inclusion of RL + VLMs + Embeddings. EPAi is an advanced Python course for those wanting to become application and ML Architects.\"\n\n    return f\"FINAL_ANSWER: {summary}\""
    },
    "tool_result": {
      "result": "FINAL_ANSWER: The School of AI (TSAI) offers courses in AI, ML, and deep learning. Their courses, ERA, EAG, and EPAi, have trained over 7000 students. ERA focuses on training LLMs from scratch, EAG focuses on Agents and EPAi is a Python and programming for AI course. EAG V2 will be in April 2026. ERA V4 introduces an exceptional course structure and includes Real-World, Full-Scale LLM Training, Practical CoreSet Focus, Multi-GPU ImageNet Training, Quantization Aware Training (QAT), and Balanced Inclusion of RL + VLMs + Embeddings. EPAi is an advanced Python course for those wanting to become application and ML Architects."
    },
    "final_answer": null,
    "tags": [
      "sandbox"
    ],
    "success": true,
    "metadata": {}
  },
  {
    "timestamp": 1764720102.103322,
    "type": "run_metadata",
    "text": "Started new session with input: let me know the current gold price in indian rupees at 2025-12-03T00:01:42.103322",
    "tool_name": null,
    "tool_args": null,
    "tool_result": null,
    "final_answer": null,
    "tags": [
      "run_start"
    ],
    "success": null,
    "metadata": {
      "start_time": "2025-12-03T00:01:42.103322",
      "step": 0
    }
  },
  {
    "timestamp": 1764720121.4019284,
    "type": "run_metadata",
    "text": "Started new session with input:  at 2025-12-03T00:02:01.401928",
    "tool_name": null,
    "tool_args": null,
    "tool_result": null,
    "final_answer": null,
    "tags": [
      "run_start"
    ],
    "success": null,
    "metadata": {
      "start_time": "2025-12-03T00:02:01.401928",
      "step": 0
    }
  },
  {
    "timestamp": 1764720129.0510926,
    "type": "tool_output",
    "text": "Output of solve_sandbox: {'result': \"[sandbox error: name 'result' is not defined]\"}",
    "tool_name": "solve_sandbox",
    "tool_args": {
      "plan": "import json\nasync def solve():\n    # NO FUNCTION_CALL - Data already provided in user input\n    # The user input already contains search results showing current gold prices in Indian Rupees.\n\n    # Extract information from the provided search results and synthesize answer\n    gold_price_info = json.loads(result.content[0].text)[\"result\"]\n\n    # FINAL_ANSWER - synthesize from data already in user_input\n    return f\"FINAL_ANSWER: {gold_price_info}\""
    },
    "tool_result": {
      "result": "[sandbox error: name 'result' is not defined]"
    },
    "final_answer": null,
    "tags": [
      "sandbox"
    ],
    "success": false,
    "metadata": {}
  },
  {
    "timestamp": 1764720134.0906115,
    "type": "tool_output",
    "text": "Output of solve_sandbox: {'result': 'FINAL_ANSWER: Current gold prices in Indian Rupees can be found on websites like goldprice.org, GoodReturns, Groww, Gadgets360, and MoneyControl. These sites provide live gold rates, including 22K and 24K gold prices per gram and 10 grams. Factors affecting gold prices include the strength of the Indian Rupee and global events like the election of Donald Trump. Check these websites for the latest updated prices.'}",
    "tool_name": "solve_sandbox",
    "tool_args": {
      "plan": "async def solve():\n    # NO FUNCTION_CALL - Data already provided in user input\n    # The user_input contains search results with titles, URLs and summaries.\n    # Synthesize the answer from the summaries.\n\n    answer = \"Current gold prices in Indian Rupees can be found on websites like goldprice.org, GoodReturns, Groww, Gadgets360, and MoneyControl. These sites provide live gold rates, including 22K and 24K gold prices per gram and 10 grams. Factors affecting gold prices include the strength of the Indian Rupee and global events like the election of Donald Trump. Check these websites for the latest updated prices.\"\n\n    # FINAL_ANSWER - synthesize from data already in user_input\n    return f\"FINAL_ANSWER: {answer}\""
    },
    "tool_result": {
      "result": "FINAL_ANSWER: Current gold prices in Indian Rupees can be found on websites like goldprice.org, GoodReturns, Groww, Gadgets360, and MoneyControl. These sites provide live gold rates, including 22K and 24K gold prices per gram and 10 grams. Factors affecting gold prices include the strength of the Indian Rupee and global events like the election of Donald Trump. Check these websites for the latest updated prices."
    },
    "final_answer": null,
    "tags": [
      "sandbox"
    ],
    "success": true,
    "metadata": {}
  }
]